{
  
    
        "post0": {
            "title": "Title",
            "content": "Desafio Kaggle - Santander Customer Transaction Prediction . Desafio em que será necessário prever a variável target do dataset. . toc:true* branch: master | badges: false | comments: false | author: brn | categores: [jupyter] | . Para acessar esta competição no Kaggle clique aqui . Para baixar os dados clique aqui . Proposta do desafio . Nossa equipe de ciência de dados está desafiando continuamente nossos algoritmos de aprendizado de máquina, trabalhando com a comunidade global de dados científicos para garantir que possamos identificar com mais precisão novas maneiras de resolver nosso desafio mais comum, problemas de classificação binária como: um cliente está satisfeito? Um cliente comprará este produto? Um cliente pode pagar este empréstimo? . Neste desafio, convidamos a Kagglers a nos ajudar a identificar quais clientes farão uma transação específica no futuro, independentemente do volume de dinheiro transacionado. Os dados fornecidos para esta competição têm a mesma estrutura que os dados reais que temos disponíveis para resolver este problema. . import pandas as pd import numpy as np from sklearn.model_selection import train_test_split from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler # Modelos from sklearn.linear_model import LogisticRegression from sklearn.neighbors import KNeighborsClassifier from sklearn.svm import SVC from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import BaggingClassifier from sklearn.ensemble import GradientBoostingClassifier from sklearn.ensemble import AdaBoostClassifier from lightgbm import LGBMClassifier # Métricas e otimização from sklearn import metrics from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score from sklearn.metrics import f1_score from sklearn.feature_selection import RFECV from sklearn.model_selection import GridSearchCV . #drive.mount(&#39;/content/drive&#39;) . data = pd.read_csv(&quot;/content/drive/MyDrive/Awari/train.csv&quot;) data.head() . ID_code target var_0 var_1 var_2 var_3 var_4 var_5 var_6 var_7 ... var_190 var_191 var_192 var_193 var_194 var_195 var_196 var_197 var_198 var_199 . 0 train_0 | 0 | 8.9255 | -6.7863 | 11.9081 | 5.0930 | 11.4607 | -9.2834 | 5.1187 | 18.6266 | ... | 4.4354 | 3.9642 | 3.1364 | 1.6910 | 18.5227 | -2.3978 | 7.8784 | 8.5635 | 12.7803 | -1.0914 | . 1 train_1 | 0 | 11.5006 | -4.1473 | 13.8588 | 5.3890 | 12.3622 | 7.0433 | 5.6208 | 16.5338 | ... | 7.6421 | 7.7214 | 2.5837 | 10.9516 | 15.4305 | 2.0339 | 8.1267 | 8.7889 | 18.3560 | 1.9518 | . 2 train_2 | 0 | 8.6093 | -2.7457 | 12.0805 | 7.8928 | 10.5825 | -9.0837 | 6.9427 | 14.6155 | ... | 2.9057 | 9.7905 | 1.6704 | 1.6858 | 21.6042 | 3.1417 | -6.5213 | 8.2675 | 14.7222 | 0.3965 | . 3 train_3 | 0 | 11.0604 | -2.1518 | 8.9522 | 7.1957 | 12.5846 | -1.8361 | 5.8428 | 14.9250 | ... | 4.4666 | 4.7433 | 0.7178 | 1.4214 | 23.0347 | -1.2706 | -2.9275 | 10.2922 | 17.9697 | -8.9996 | . 4 train_4 | 0 | 9.8369 | -1.4834 | 12.8746 | 6.6375 | 12.2772 | 2.4486 | 5.9405 | 19.2514 | ... | -1.4905 | 9.5214 | -0.1508 | 9.1942 | 13.2876 | -1.5121 | 3.9267 | 9.5031 | 17.9974 | -8.8104 | . 5 rows × 202 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Como o dataset foi distribuido de forma a ocultar o que são as variaveis, fica infactivel fazer uma engenharia de features. . data.shape . (200000, 202) . data.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 200000 entries, 0 to 199999 Columns: 202 entries, ID_code to var_199 dtypes: float64(200), int64(1), object(1) memory usage: 308.2+ MB . Avaliando o target . data[&#39;target&#39;].value_counts() . 0 179902 1 20098 Name: target, dtype: int64 . Importante lembrar que em um problema de classificação caso os dados estejam desbalanceados, que é o caso, é preciso tomar alguma medidas para corrigir isso. . X = data.drop(columns=[&#39;ID_code&#39;, &#39;target&#39;]) y = data[&#39;target&#39;] . X_train, X_test, y_train, y_test = train_test_split(X, y) . 1 - Regress&#227;o Logistica . pipe_reglog = make_pipeline(StandardScaler(), LogisticRegression()) pipe_reglog.fit(X_train, y_train) y_pred = pipe_reglog.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.6736465781409602 Acuracia 0.9127 Recall 0.26144697720515364 Roc 0.6236163814954696 f1 0.37669570184206774 . A acurácia não é uma boa métrica para dados desbalanceados . Regress&#227;o Logistica + Balanceamento . pipe_reglog = make_pipeline(StandardScaler(), LogisticRegression(class_weight=&#39;balanced&#39;)) pipe_reglog.fit(X_train, y_train) y_pred = pipe_reglog.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.28119276137445964 Acuracia 0.78094 Recall 0.7706827309236948 Roc 0.7763786822099593 f1 0.41204573514413007 . Regress&#227;o Logistica + Balanceamento + RFE . pipe_rfe_reglog = make_pipeline(StandardScaler(), RFECV(LogisticRegression(class_weight=&#39;balanced&#39;), step=1, cv=5), LogisticRegression(class_weight=&#39;balanced&#39;) ) pipe_rfe_reglog.fit(X_train, y_train) y_pred = pipe_rfe_reglog.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.2814972165250513 Acuracia 0.78108 Recall 0.7716867469879518 Roc 0.7769029025921546 f1 0.41251610133104333 . 2 - KNeighbors . for i in range(1, 10): pipe_neigh = make_pipeline(KNeighborsClassifier(n_neighbors=i)) pipe_neigh.fit(X_train, y_train) y_pred = pipe_neigh.predict(X_test) print(i) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;-&#39;) . pipe_neigh = make_pipeline(KNeighborsClassifier(n_neighbors=3)) pipe_neigh.fit(X_train, y_train) y_pred = pipe_neigh.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.20738636363636365 Acuracia 0.89572 Recall 0.01457667731629393 Roc 0.504187787449043 f1 0.027238805970149257 . 3 - SVM/SVC . pipe_svc = make_pipeline(StandardScaler(), SVC()) pipe_svc.fit(X_train, y_train) y_pred = pipe_svc.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.7976111479761114 Acuracia 0.91778 Recall 0.24001597444089456 Roc 0.6166184957552979 f1 0.36899462778204145 . SVM/SVC + Balanceamento . pipe_svc = make_pipeline(StandardScaler(), SVC(class_weight=&#39;balanced&#39;)) pipe_svc.fit(X_train, y_train) y_pred = pipe_svc.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.4462006079027356 Acuracia 0.88442 Recall 0.5789785052257937 Roc 0.7489363803032528 f1 0.5039910737275771 . 4 - &#193;rvore de Decis&#227;o . tree = DecisionTreeClassifier() tree.fit(X_train, y_train) y_pred = tree.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.2814972165250513 Acuracia 0.78108 Recall 0.7716867469879518 Roc 0.7769029025921546 f1 0.41251610133104333 . &#193;rvore de Decis&#227;o + Balanceamento . tree = DecisionTreeClassifier(class_weight=&#39;balanced&#39;) tree.fit(X_train, y_train) y_pred = tree.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.1629139072847682 Acuracia 0.82554 Recall 0.16686046511627908 Roc 0.5340992780532332 f1 0.16486357108664434 . 6 - &#193;rvore de Decis&#227;o + Otimiza&#231;&#227;o de Hiperparametros (ROC) . from sklearn import metrics metrics.SCORERS.keys() # Nome dos parametros de socring . params = { #&#39;splitter&#39;: [&#39;best&#39;, &#39;random&#39;], &#39;max_depth&#39;: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], #3, 4, 5, 6, 7, 8, 9, &#39;min_samples_split&#39;: [40, 60, 80, 100]#,2, 10, 20, #&#39;class_weight&#39;: [&#39;balanced&#39;, None] } #Por padrão o modelo escolhe a métrica acurácia para escolher os parametros grid = GridSearchCV(DecisionTreeClassifier(), params, scoring=&#39;roc_auc&#39;) grid.fit(X_train, y_train) . GridSearchCV(estimator=DecisionTreeClassifier(), param_grid={&#39;max_depth&#39;: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], &#39;min_samples_split&#39;: [40, 60, 80, 100]}, scoring=&#39;roc_auc&#39;) . Na primeira rodada do grid tivemos {&#39;max_depth&#39;: 10, &#39;min_samples_split&#39;: 40} como melhores parametros, então decidi aumentar esses parametros e rodar de novo . grid.best_params_ . {&#39;max_depth&#39;: 13, &#39;min_samples_split&#39;: 100} . modelo = grid.best_estimator_ y_pred = modelo.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.31109550561797755 Acuracia 0.8895 Recall 0.08883096049729296 Roc 0.5335186282281191 f1 0.1381999688036188 . Melhores parametros {&#39;max_depth&#39;: 10, &#39;min_samples_split&#39;: 40} . Precision 0.3295099061522419 | Acuracia 0.89372 | Recall 0.06336474834569882 | Roc 0.524539993082942 | f1 0.10628994281870163 | . 5 - Bagging (&#193;rvore de Decis&#227;o) . bdt = BaggingClassifier(DecisionTreeClassifier(max_depth=13, min_samples_split=100)).fit(X_train, y_train) y_pred = bdt.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.6455696202531646 Acuracia 0.89726 Recall 0.009883720930232558 Roc 0.5046296392340726 f1 0.019469364382515744 . Bagging (&#193;rvore de Decis&#227;o + Balanceamento) . bdt = BaggingClassifier(DecisionTreeClassifier(max_depth=13, min_samples_split=100, class_weight=&#39;balanced&#39;)).fit(X_train, y_train) y_pred = bdt.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.2717852096090438 Acuracia 0.83866 Recall 0.3354651162790698 Roc 0.6160153413687945 f1 0.30028623471246424 . bdt = BaggingClassifier(DecisionTreeClassifier(max_depth=13, min_samples_split=100)).fit(X_train, y_train) y_pred = bdt.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.6842105263157895 Acuracia 0.90054 Recall 0.005213555243633447 Roc 0.5024734827958776 f1 0.010348258706467661 . 6 - Floresta Randomica . rf = RandomForestClassifier().fit(X_train, y_train) y_pred = rf.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.0 Acuracia 0.90026 Recall 0.0 Roc 0.5 f1 0.0 . /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . Floresta Randomica + Balanceamento . rf = RandomForestClassifier(class_weight=&#39;balanced&#39;).fit(X_train, y_train) y_pred = rf.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.0 Acuracia 0.8968 Recall 0.0 Roc 0.5 f1 0.0 . /usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . 7 - AdaBoost . ada = AdaBoostClassifier( DecisionTreeClassifier() ) ada.fit(X_train, y_train) y_pred = ada.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.8756476683937824 Acuracia 0.9015 Recall 0.03333333333333333 Roc 0.5163995845389124 f1 0.06422192665779973 . 8 - Gradient Boosting . gbm = GradientBoostingClassifier() gbm.fit(X_train, y_train) y_pred = gbm.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.8756476683937824 Acuracia 0.9015 Recall 0.03333333333333333 Roc 0.5163995845389124 f1 0.06422192665779973 . 9 - Lightgbm . light = LGBMClassifier() light.fit(X_train, y_train) y_pred = light.predict(X_test) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.8605042016806723 Acuracia 0.90538 Recall 0.09922480620155039 Roc 0.5486868901658957 f1 0.17793223284100781 . light = LGBMClassifier( metric = &#39;auc&#39;, objective = &#39;binary&#39;, ) light.fit(X_train, y_train) y_pred = light.predict(X_test) . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.8641975308641975 Acuracia 0.9082 Recall 0.0979412352588447 Roc 0.548115005033027 f1 0.17594254937163376 . light = LGBMClassifier( metric = &#39;auc&#39;, objective = &#39;binary&#39;, is_unbalance = True, n_jobs = -1, verbose = -1, # Parâmetros de https://www.kaggle.com/code/dott1718/922-in-3-minutes/notebook learning_rate = 0.05, max_bin = 165, max_depth = 5, min_child_samples = 150, min_child_weight = 0.1, min_split_gain = 0.0018, n_estimators = 41, num_leaves = 6, reg_alpha = 2.0, reg_lambda = 2.54, ) light.fit(X_train, y_train) y_pred = light.predict(X_test) . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . Precision 0.2912285042682172 Acuracia 0.83244 Recall 0.4705176893863682 Roc 0.6715990451509923 f1 0.35977380406541337 . msg = &quot;Terminou de calcular o modelo tudo&quot; # enviar a mensagem send_message(token1, id1, msg) . Minha abordagem . Adicionando uma nova coluna com clusteriza&#231;&#227;o . from sklearn.cluster import KMeans from sklearn.preprocessing import StandardScaler import matplotlib.pyplot as plt import seaborn as sns from sklearn.metrics import silhouette_score from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer from sklearn.cluster import SpectralClustering from sklearn.cluster import AgglomerativeClustering from sklearn.mixture import GaussianMixture . data1 = data data1.head() . ID_code target var_0 var_1 var_2 var_3 var_4 var_5 var_6 var_7 ... var_190 var_191 var_192 var_193 var_194 var_195 var_196 var_197 var_198 var_199 . 0 train_0 | 0 | 8.9255 | -6.7863 | 11.9081 | 5.0930 | 11.4607 | -9.2834 | 5.1187 | 18.6266 | ... | 4.4354 | 3.9642 | 3.1364 | 1.6910 | 18.5227 | -2.3978 | 7.8784 | 8.5635 | 12.7803 | -1.0914 | . 1 train_1 | 0 | 11.5006 | -4.1473 | 13.8588 | 5.3890 | 12.3622 | 7.0433 | 5.6208 | 16.5338 | ... | 7.6421 | 7.7214 | 2.5837 | 10.9516 | 15.4305 | 2.0339 | 8.1267 | 8.7889 | 18.3560 | 1.9518 | . 2 train_2 | 0 | 8.6093 | -2.7457 | 12.0805 | 7.8928 | 10.5825 | -9.0837 | 6.9427 | 14.6155 | ... | 2.9057 | 9.7905 | 1.6704 | 1.6858 | 21.6042 | 3.1417 | -6.5213 | 8.2675 | 14.7222 | 0.3965 | . 3 train_3 | 0 | 11.0604 | -2.1518 | 8.9522 | 7.1957 | 12.5846 | -1.8361 | 5.8428 | 14.9250 | ... | 4.4666 | 4.7433 | 0.7178 | 1.4214 | 23.0347 | -1.2706 | -2.9275 | 10.2922 | 17.9697 | -8.9996 | . 4 train_4 | 0 | 9.8369 | -1.4834 | 12.8746 | 6.6375 | 12.2772 | 2.4486 | 5.9405 | 19.2514 | ... | -1.4905 | 9.5214 | -0.1508 | 9.1942 | 13.2876 | -1.5121 | 3.9267 | 9.5031 | 17.9974 | -8.8104 | . 5 rows × 202 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; data1.isna().sum() . ID_code 0 target 0 var_0 0 var_1 0 var_2 0 .. var_195 0 var_196 0 var_197 0 var_198 0 var_199 0 Length: 202, dtype: int64 . data1 = data1.drop(columns=[&#39;ID_code&#39;]) . # pois é um algoritmo baseado em distância. scaler = StandardScaler() X = scaler.fit_transform(data1) . kmeans = KMeans(n_clusters=2, random_state=0) kmeans.fit(X) . KMeans(n_clusters=2, random_state=0) . kmeans.inertia_ . 39955764.096667096 . # aparentemente com 4 clusters tem a meior queda no erro erro = [] for i in range(2, 11): kmeans = KMeans(n_clusters=i, random_state=0) kmeans.fit(X) erro.append( kmeans.inertia_ ) plt.plot( range(2,11), erro) . [&lt;matplotlib.lines.Line2D at 0x7f1fbd2cb450&gt;] . fig, ax = plt.subplots(3, 2, figsize=(15,8)) for i in [2, 3, 4, 5, 6, 7]: &#39;&#39;&#39; Create KMeans instance for different number of clusters &#39;&#39;&#39; km = KMeans(n_clusters=i, init=&#39;k-means++&#39;, n_init=10, max_iter=100, random_state=42) q, mod = divmod(i, 2) &#39;&#39;&#39; Create SilhouetteVisualizer instance with KMeans instance Fit the visualizer &#39;&#39;&#39; visualizer = SilhouetteVisualizer(km, colors=&#39;yellowbrick&#39;, ax=ax[q-1][mod]) visualizer.fit(X) . kmeans = KMeans(n_clusters=4, random_state=0) # Primeira tentativa foi com 6 labels = kmeans.fit_predict(X) . data1[&#39;cluster&#39;] = labels . data1.head() . target var_0 var_1 var_2 var_3 var_4 var_5 var_6 var_7 var_8 ... var_191 var_192 var_193 var_194 var_195 var_196 var_197 var_198 var_199 cluster . 0 0 | 8.9255 | -6.7863 | 11.9081 | 5.0930 | 11.4607 | -9.2834 | 5.1187 | 18.6266 | -4.9200 | ... | 3.9642 | 3.1364 | 1.6910 | 18.5227 | -2.3978 | 7.8784 | 8.5635 | 12.7803 | -1.0914 | 0 | . 1 0 | 11.5006 | -4.1473 | 13.8588 | 5.3890 | 12.3622 | 7.0433 | 5.6208 | 16.5338 | 3.1468 | ... | 7.7214 | 2.5837 | 10.9516 | 15.4305 | 2.0339 | 8.1267 | 8.7889 | 18.3560 | 1.9518 | 1 | . 2 0 | 8.6093 | -2.7457 | 12.0805 | 7.8928 | 10.5825 | -9.0837 | 6.9427 | 14.6155 | -4.9193 | ... | 9.7905 | 1.6704 | 1.6858 | 21.6042 | 3.1417 | -6.5213 | 8.2675 | 14.7222 | 0.3965 | 1 | . 3 0 | 11.0604 | -2.1518 | 8.9522 | 7.1957 | 12.5846 | -1.8361 | 5.8428 | 14.9250 | -5.8609 | ... | 4.7433 | 0.7178 | 1.4214 | 23.0347 | -1.2706 | -2.9275 | 10.2922 | 17.9697 | -8.9996 | 2 | . 4 0 | 9.8369 | -1.4834 | 12.8746 | 6.6375 | 12.2772 | 2.4486 | 5.9405 | 19.2514 | 6.2654 | ... | 9.5214 | -0.1508 | 9.1942 | 13.2876 | -1.5121 | 3.9267 | 9.5031 | 17.9974 | -8.8104 | 2 | . 5 rows × 202 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; X = data1.drop(columns=[&#39;target&#39;]) y = data1[&#39;target&#39;] . Variando propor&#231;&#227;o treino/teste . for i in [0.1, 0.2, 0.25, 0.3, 0.33, 0.5]: X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=i) pipe_rfe_reglog = make_pipeline(StandardScaler(), RFECV(LogisticRegression(class_weight=&#39;balanced&#39;), step=1, cv=5), LogisticRegression(class_weight=&#39;balanced&#39;) ) pipe_rfe_reglog.fit(X_train, y_train) y_pred = pipe_rfe_reglog.predict(X_test) print(i) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;--&#39;) . 0.1 Roc 0.7739683352912049 -- 0.2 Roc 0.776714549619299 -- 0.25 Roc 0.7768361463903743 -- 0.3 Roc 0.7795311513573233 -- 0.33 Roc 0.7804075834199172 -- 0.5 Roc 0.7797296816518016 -- . for i in [0.1, 0.2, 0.25, 0.3, 0.33, 0.5]: X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=i) pipe_rfe_reglog = make_pipeline(StandardScaler(), RFECV(LogisticRegression(class_weight=&#39;balanced&#39;), step=1, cv=5), LogisticRegression(class_weight=&#39;balanced&#39;) ) pipe_rfe_reglog.fit(X_train, y_train) y_pred = pipe_rfe_reglog.predict(X_test) print(i) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;--&#39;) . 0.1 Roc 0.999754058042302 -- 0.2 Roc 0.9996338784476446 -- 0.25 Roc 0.99970703125 -- 0.3 Roc 0.999755859375 -- 0.33 Roc 0.9997779093870299 -- 0.5 Roc 0.9997534030380746 -- . for i in [0.1, 0.2, 0.25, 0.3, 0.33, 0.5]: X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=i) pipe_rfe_reglog = make_pipeline(StandardScaler(), RFECV(LogisticRegression(class_weight=&#39;balanced&#39;), step=1, cv=5), LogisticRegression(class_weight=&#39;balanced&#39;) ) pipe_rfe_reglog.fit(X_train, y_train) y_pred = pipe_rfe_reglog.predict(X_test) print(i) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;--&#39;) . 0.1 Roc 0.999508116084604 -- 0.2 Roc 0.9997559189650964 -- 0.25 Roc 0.9998046875 -- 0.3 Roc 0.999755859375 -- 0.33 Roc 0.9997779093870299 -- 0.5 Roc 0.9997040836456894 -- . Melhorando Hiperparametros com GridSearch . X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.33) . from sklearn.pipeline import Pipeline . pipe_rfe_reglog = Pipeline( [ (&quot;std&quot;, StandardScaler()), (&quot;RFE&quot;, RFECV(LogisticRegression(class_weight=&#39;balanced&#39;), scoring=&#39;roc_auc&#39;)), (&quot;class&quot;, LogisticRegression(class_weight=&#39;balanced&#39;)) ] ) . params = { &#39;RFE__step&#39; : [1, 2, 3, 4, 5], &#39;RFE__cv&#39; : [3, 4, 5, 6, 7], &#39;RFE__min_features_to_select&#39;: [1, 2, 3], &#39;class__multi_class&#39;: [&#39;auto&#39;, &#39;ovr&#39;, &#39;multinomial&#39;] } grid = GridSearchCV(pipe_rfe_reglog, params, #cv = 20, scoring = &#39;roc_auc&#39;) . grid.best_params_ . AttributeError Traceback (most recent call last) &lt;ipython-input-50-28c2e4d7952c&gt; in &lt;module&gt;() -&gt; 1 grid.best_params_ AttributeError: &#39;GridSearchCV&#39; object has no attribute &#39;best_params_&#39; . modelo = grid.best_estimator_ y_pred = modelo.predict(X_test) . AttributeError Traceback (most recent call last) &lt;ipython-input-48-2149ca5ec6cb&gt; in &lt;module&gt;() -&gt; 1 modelo = grid.best_estimator_ 2 y_pred = modelo.predict(X_test) AttributeError: &#39;GridSearchCV&#39; object has no attribute &#39;best_estimator_&#39; . pd.DataFrame(grid.cv_results_) . ConfusionMatrixDisplay.from_predictions(y_test, y_pred); . print(&#39;Precision&#39;, precision_score(y_test, y_pred)) print(&#39;Acuracia&#39;, accuracy_score(y_test, y_pred)) print(&#39;Recall&#39;, recall_score(y_test, y_pred)) print(&#39;Roc&#39;, roc_auc_score(y_test, y_pred)) print(&#39;f1&#39;, f1_score(y_test, y_pred)) . msg = &quot;Terminou de calcular o modelo&quot; # enviar a mensagem send_message(token1, id1, msg) . Abordagem vencedora do desafio . Interpreta&#231;&#227;o do modelo SHAP .",
            "url": "https://brncode.github.io/Projetos/2022/08/21/.html",
            "relUrl": "/2022/08/21/.html",
            "date": " • Aug 21, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://brncode.github.io/Projetos/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://brncode.github.io/Projetos/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://brncode.github.io/Projetos/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}